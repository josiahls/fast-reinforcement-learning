{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Can't import one of these: No module named 'pybulletgym.envs.mujoco.envs'\n",
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f82109af2097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_train\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseDQNCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentInterpretation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGroupAgentInterpretation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_block\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMDPDataBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperienceReplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGreedyEpsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPriorityExperienceReplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DQN' from 'fast_rl.agents.dqn' (/Users/jlaivins/PycharmProjects/fast-reinforcement-learning/fast_rl/agents/dqn.py)"
     ],
     "ename": "ImportError",
     "evalue": "cannot import name 'DQN' from 'fast_rl.agents.dqn' (/Users/jlaivins/PycharmProjects/fast-reinforcement-learning/fast_rl/agents/dqn.py)",
     "output_type": "error"
    }
   ],
   "source": [
    "from fast_rl.core.basic_train import AgentLearner\n",
    "from fast_rl.agents.dqn import DQN, BaseDQNCallback\n",
    "from fast_rl.core.train import AgentInterpretation, GroupAgentInterpretation\n",
    "from fast_rl.core.data_block import MDPDataBunch\n",
    "from fast_rl.core.agent_core import ExperienceReplay, GreedyEpsilon, PriorityExperienceReplay\n",
    "import torch\n",
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.basic_data import DatasetType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databunch for Training / Validation\n",
    "For reinforcement learning, training might take a long time.\n",
    "\n",
    "Note that if you want to avoid validation running, just turn it off and reflect the change in \n",
    "the interpretation objects. The agent will train much faster, and then you could validate later.\n",
    "```python\n",
    "data = MDPDataBunch.from_env('CartPole-v1', render='rgb_array', add_valid=False, bs=128)\n",
    "AgentInterpretation(learn=learn, ds_type=DatasetType.Train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = MDPDataBunch.from_env('CartPole-v1', render='rgb_array', bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "show_doc(DQN.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "show_doc(BaseDQNCallback.__init__)\n",
    "show_doc(BaseDQNCallback.on_loss_begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size will be defined in the data class because `DataBunches` already require a \n",
    "batch size input. This batch size will be used by the model during optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = DQN(data, memory=ExperienceReplay(memory_size=100000, reduce_ram=True),\n",
    "           lr=0.00025, optimizer=torch.optim.RMSprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "learn = AgentLearner(data, model)\n",
    "learn.fit(450)\n",
    "data.close()\n",
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "interp = AgentInterpretation(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "interp.plot_rewards(cumulative=True, per_episode=True, group_name='er_rms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pipe-line this to truly see how our model actually performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "group_interp = GroupAgentInterpretation()\n",
    "group_interp.add_interpretation(interp)\n",
    "for i in range(5):\n",
    "    data = MDPDataBunch.from_env('CartPole-v1', render='rgb_array', bs=32, add_valid=False)\n",
    "    model = DQN(data, memory=ExperienceReplay(memory_size=1000000, reduce_ram=True),\n",
    "                lr=0.001, optimizer=torch.optim.RMSprop)\n",
    "    learn = AgentLearner(data, model)\n",
    "    learn.fit(450)\n",
    "    interp = AgentInterpretation(learn, ds_type=DatasetType.Train)\n",
    "    interp.plot_rewards(cumulative=True, per_episode=True, group_name='er_rms', no_show=True)\n",
    "    group_interp.add_interpretation(interp)\n",
    "    group_interp.to_pickle('data/dqn', 'dqn_er_rms')\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "group_interp = GroupAgentInterpretation.from_pickle('data/cartpole_dqn', 'dqn_ExperienceReplay_FEED_TYPE_STATE')\n",
    "group_interp.plot_reward_bounds(per_episode=True, smooth_groups=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "[g.analysis for g in group_interp.groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "per_group_interp = GroupAgentInterpretation()\n",
    "per_group_interp.add_interpretation(interp)\n",
    "for i in range(4):\n",
    "    data = MDPDataBunch.from_env('CartPole-v1', render='rgb_array', bs=32)\n",
    "    model = DQN(data, memory=PriorityExperienceReplay(memory_size=100000, reduce_ram=True))\n",
    "    learn = AgentLearner(data, model)\n",
    "    learn.fit(450)\n",
    "    interp = AgentInterpretation(learn, ds_type=DatasetType.Train)\n",
    "    interp.plot_rewards(cumulative=True, per_episode=True, group_name='per_rms', no_show=True)\n",
    "    per_group_interp.add_interpretation(interp)\n",
    "    group_interp.to_pickle('data/dqn', 'dqn_per')\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "per_group_interp = GroupAgentInterpretation.from_pickle('data/cartpole_dqn', 'dqn_PriorityExperienceReplay_FEED_TYPE_STATE')\n",
    "per_group_interp.add_interpretation(group_interp)\n",
    "per_group_interp.plot_reward_bounds(per_episode=True, smooth_groups=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CartPole envs might be too simple for PER to be effective. We also tested with lunar lander to see if PER improves performance, and noticed that it actually performs worse than ER. There is a possibility that you could increase the random sampling for PER to see if there is an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "per_group_interp = GroupAgentInterpretation.from_pickle('data/lunarlander_dqn', 'dqn_ExperienceReplay_FEED_TYPE_STATE')\n",
    "per_group_interp.add_interpretation(\n",
    "    GroupAgentInterpretation.from_pickle('data/lunarlander_dqn', 'dqn_PriorityExperienceReplay_FEED_TYPE_STATE')\n",
    ")\n",
    "per_group_interp.plot_reward_bounds(per_episode=True, smooth_groups=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "per_group_interp.analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}